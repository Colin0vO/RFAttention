{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2faf074",
   "metadata": {},
   "source": [
    "# Method2: Maclurain Random Feature implemented on one row of softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a71a20",
   "metadata": {},
   "source": [
    "# Precompute all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba8c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# ——— Load and prepare q0, k0 as NumPy arrays ———\n",
    "q_full = torch.load(\"subset_qk/block_1_q_proj_batch_6.pt\", map_location=\"cpu\")\n",
    "k_full = torch.load(\"subset_qk/block_1_k_proj_batch_6.pt\", map_location=\"cpu\")\n",
    "\n",
    "q = q_full[0]  # shape [L, d_model]\n",
    "k = k_full[0]\n",
    "\n",
    "L, d_model = q.shape\n",
    "num_heads  = 32\n",
    "d_head     = d_model // num_heads\n",
    "\n",
    "# pick head 15 and first `sample` positions\n",
    "sample = 4096\n",
    "def sampling(q, k, sample):\n",
    "    q0 = (\n",
    "        q\n",
    "        .view(L, num_heads, d_head)\n",
    "        .permute(1, 0, 2)[15, :sample]\n",
    "        .numpy()\n",
    "    )   # shape [sample, d_head]\n",
    "    k0 = (\n",
    "        k\n",
    "        .view(L, num_heads, d_head)\n",
    "        .permute(1, 0, 2)[15, :sample]\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    q0 = q0 / 128 ** 0.25\n",
    "    k0 = k0 / 128 ** 0.25\n",
    "    \n",
    "    return q0, k0\n",
    "\n",
    "\n",
    "def rfa_attention_fast(q0, k0, P=8, D=2000, shrink=10.0, power=100):\n",
    "    \"\"\"\n",
    "    q0, k0:  (N, d) arrays of queries & keys\n",
    "    returns: (N, N) approximate softmax(QK^T)\n",
    "    \"\"\"\n",
    "    # 1) Pre-scale and cast to float32\n",
    "    X = (q0 / shrink).astype(np.float64)   # (N, d)\n",
    "    Y = (k0 / shrink).astype(np.float64)\n",
    "\n",
    "    N, d = X.shape\n",
    "\n",
    "    # 2) Sample ±1 weights in one flat block, cast to float32\n",
    "    #    shape = (P*D, d)\n",
    "    w_flat = np.sign(np.random.randn(P * D, d)).astype(np.float64)\n",
    "\n",
    "    # 3) One mat-mul to get all projections, then reshape to (N,P,D)\n",
    "    #    proj_x[n, p*D + j] = w_flat[p*D + j] ⋅ X[n]\n",
    "    proj_x_flat = X.dot(w_flat.T)           # (N, P*D)\n",
    "    proj_y_flat = Y.dot(w_flat.T)\n",
    "\n",
    "    proj_x = proj_x_flat.reshape(N, P, D)   # (N, P, D)\n",
    "    proj_y = proj_y_flat.reshape(N, P, D)\n",
    "\n",
    "    # 4) Build per-degree normalizers √(D·p!) for p=1..P\n",
    "    facts = np.array([math.sqrt(math.factorial(p+1)) for p in range(P)],\n",
    "                     dtype=np.float64)     # (P,)\n",
    "    normalizer = np.sqrt(D, dtype=np.float64) * facts\n",
    "    normalizer = normalizer.reshape(1, P, 1)  # (1, P, 1)\n",
    "\n",
    "    # 5) Cumulative product along the P-axis to get φ_p\n",
    "    #    φ_p = ∏_{m=1..p} (proj[...,m-1] / normalizer[...,m-1])\n",
    "    phi_x = np.cumprod(proj_x / normalizer, axis=1)  # (N, P, D)\n",
    "    phi_y = np.cumprod(proj_y / normalizer, axis=1)\n",
    "\n",
    "    # 6) Flatten φ back to (N, P*D)\n",
    "    phi_x_flat = phi_x.reshape(N, P * D)\n",
    "    phi_y_flat = phi_y.reshape(N, P * D)\n",
    "\n",
    "    # 7) One big BLAS mat-mul to form the kernel matrix\n",
    "    S = phi_x_flat.dot(phi_y_flat.T)  # (N, N)\n",
    "\n",
    "    # 8) Sharpen & row-normalize\n",
    "    M = (1.0 + S) ** power\n",
    "    M /= M.max(axis=1, keepdims=True)\n",
    "    M /= M.sum(axis=1, keepdims=True)\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "# usage:\n",
    "# approx = rfa_attention_vectorized(q0, k0)\n",
    "\n",
    "def true_softmax(q0, k0):\n",
    "    dot = q0 @ k0.T\n",
    "    true_val = np.exp(dot - dot.max(axis=1, keepdims=True))\n",
    "    true_val /= true_val.sum(axis=1, keepdims=True)\n",
    "    return true_val\n",
    "\n",
    "def report_error(record_approx_values, true_val):\n",
    "    return torch.norm(torch.tensor(record_approx_values - true_val)) / torch.norm(torch.tensor(true_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa99cd7",
   "metadata": {},
   "source": [
    "# Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa70ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, D, d = 4, 2000, 128\n",
    "sample=4096\n",
    "q0, k0 = sampling(q, k, sample)\n",
    "v0 =(q0+ 4 * k0) /3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe3e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_approx_values = rfa_attention_fast(q0, k0, P, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad27dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_v=record_approx_values @ v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bfdfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = true_softmax(q0, k0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d70763",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val = true_vals @ v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7787d576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2230, dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.norm(torch.tensor(record_approx_values - true_vals)) / torch.norm(torch.tensor(true_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a1ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c7e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0246, dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.norm(torch.tensor(approx_v - true_val)) / torch.norm(torch.tensor(true_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
